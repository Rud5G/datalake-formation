AWSTemplateFormatVersion: 2010-09-09
Description: Producer account Lake Formation setups for cross-account sharing scenario

Parameters:
  ProducerDatalakeAdminUserName:
    Type: String
    Description: IAM user name to be created for data lake admin.
    Default: DatalakeAdminProducer
    AllowedPattern: '[\w+=,.@-]+'
    MinLength: '1'
    MaxLength: '64'
    ConstraintDescription: the user name must be between 1 and 64 characters
  ProducerDatalakeAdminUserPassword:
    Type: String
    Description: IAM user console password for data lake admin.
    NoEcho: 'true'
    AllowedPattern: '[\u0009\u000A\u000D\u0020-\u00FF]+'
    MinLength: '1'
    MaxLength: '128'
    ConstraintDescription: the password must be between 1 and 128 characters
  DataLakeBucketName:
    Type: String
    Description: S3 bucket name to be created to store data for data lake. The name needs to be globally unique.
  DatabaseNameTbac:
    Type: String
    Description: Lake Formation database name to be created to store a table. This database will be shared using the tbac method.
    Default: lakeformation_tutorial_cross_account_database_tbac
  DatabaseNameNamedResource:
    Type: String
    Description: Lake Formation database name to be created to store a table. This database will be shared using the named resources method.
    Default: lakeformation_tutorial_cross_account_database_named_resource
  TableNameTbac:
    Type: String
    Description: Lake Formation table name to be created to point Amazon Customer Reviews Dataset. This table will be shared using the tbac method.
    Default: amazon_reviews_table_tbac
  TableNameNamedResource:
    Type: String
    Description: Lake Formation table name to be created to point Amazon Customer Reviews Dataset. This table will be shared using the named resource method.
    Default: amazon_reviews_table_named_resource

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: IAM User Configuration
        Parameters:
          - ProducerDatalakeAdminUserName
          - ProducerDatalakeAdminUserPassword
      -
        Label:
          default: Data Lake Configuration
        Parameters:
          - DataLakeBucketName
          - DatabaseNameTbac
          - DatabaseNameNamedResource
          - TableNameTbac
          - TableNameNamedResource

Resources:
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub ${DataLakeBucketName}
      AccessControl: Private
      PublicAccessBlockConfiguration:
        BlockPublicAcls: True
        BlockPublicPolicy: True
        IgnorePublicAcls: True
        RestrictPublicBuckets: True

  S3CustomResource:
    DependsOn: S3Bucket
    Type: Custom::S3CustomResource
    Properties:
      ServiceToken: !GetAtt AWSLambdaFunction.Arn
      the_data_bucket: !Sub ${DataLakeBucketName}
      the_data_key_prefix: 'data/amazon_reviews_parquet/product_category=Video/'
      the_origin_data_bucket: 'amazon-reviews-pds'
      the_origin_data_key_prefix: 'parquet/product_category=Video/'

  AWSLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Description: "Custom resource for S3"
      FunctionName: !Sub 'lambda-custom-resource-${AWS::StackName}'
      Handler: index.handler
      Role: !GetAtt AWSLambdaExecutionRole.Arn
      Timeout: 360
      Runtime: python3.8
      Code:
        ZipFile: !Sub
          - |
            import boto3
            from botocore.client import ClientError
            import cfnresponse
            def handler(event, context):
                # Init
                the_event = event['RequestType'].strip()
                print("The event is: ", the_event)
                response_data = {}
                s3 = boto3.client('s3')
                # Retrieve parameters
                the_data_bucket = event['ResourceProperties']['the_data_bucket'].strip()
                the_data_key_prefix = event['ResourceProperties']['the_data_key_prefix'].strip()
                the_origin_data_bucket = event['ResourceProperties']['the_origin_data_bucket'].strip()
                the_origin_data_key_prefix = event['ResourceProperties']['the_origin_data_key_prefix'].strip()
                try:
                    if the_event in ('Create', 'Update'):
                        try:
                          response= s3.list_objects_v2(Bucket=the_origin_data_bucket, Prefix=the_origin_data_key_prefix, Delimiter="/")
                          for source in response["Contents"]:
                            raw_name = source["Key"].split("/")[-1]
                            copy_source = {'Bucket': the_origin_data_bucket, 'Key': source["Key"]}
                            s3.copy_object(CopySource=copy_source, Bucket=the_data_bucket, Key=the_data_key_prefix + raw_name)
                        except ClientError as ce:
                            print("Failed to copy the source code file.")
                            print(ce)
                            print(ce.response['ResponseMetadata'])
                    elif the_event == 'Delete':
                        try:
                          response= s3.list_objects_v2(Bucket=the_data_bucket, Prefix='data/')
                          for source in response["Contents"]:
                            s3.delete_object(Bucket=the_data_bucket,Key=source["Key"])
                        except ClientError as ce:
                            print(f"Failed to delete the files: {ce}")

                    # Everything OK... send the signal back
                    print("Completed.")
                    cfnresponse.send(event,
                                      context,
                                      cfnresponse.SUCCESS,
                                      response_data)
                except Exception as e:
                    print("Failed...")
                    print(str(e))
                    response_data['Data'] = str(e)
                    cfnresponse.send(event,
                                      context,
                                      cfnresponse.FAILED,
                                      response_data)
          - Region: !Ref AWS::Region

  AWSLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub AWSLambdaExecutionRole-${AWS::StackName}
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: '2012-10-17'
      Path: "/"
      Policies:
        - PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Effect: Allow
                Resource: arn:aws:logs:*:*:*
          PolicyName: !Sub AWSLambda-CW-${AWS::StackName}
        - PolicyDocument:
            Version: '2012-10-17'
            Statement:
              -
                Effect: "Allow"
                Action:
                  - s3:GetObject
                Resource: !Sub arn:aws:s3:::amazon-reviews-pds/*
              -
                Effect: "Allow"
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                Resource:
                  - !Sub arn:aws:s3:::${DataLakeBucketName}/*
              -
                Effect: "Allow"
                Action:
                  - s3:CreateBucket
                  - s3:ListBucket
                Resource:
                  - !Sub arn:aws:s3:::${DataLakeBucketName}
                  - !Sub arn:aws:s3:::amazon-reviews-pds
          PolicyName: !Sub AWSLambda-S3-${AWS::StackName}

  DatalakeAdminUser:
    Type: AWS::IAM::User
    Properties:
      UserName: !Ref ProducerDatalakeAdminUserName
      LoginProfile:
        Password: !Ref ProducerDatalakeAdminUserPassword
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLakeFormationDataAdmin
        - arn:aws:iam::aws:policy/AWSLakeFormationCrossAccountManager
        - arn:aws:iam::aws:policy/AmazonAthenaFullAccess
        - arn:aws:iam::aws:policy/IAMReadOnlyAccess

  LFDataLakeSettings:
    Type: AWS::LakeFormation::DataLakeSettings
    Properties:
      Admins:
        - DataLakePrincipalIdentifier: !GetAtt 'DatalakeAdminUser.Arn'

  LFDataLakeLocation:
    Type: AWS::LakeFormation::Resource
    Properties:
      ResourceArn: !Sub arn:aws:s3:::${DataLakeBucketName}
      RoleArn: !GetAtt 'LFRegisterLocationServiceRole.Arn'
      UseServiceLinkedRole: false

  LFRegisterLocationServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lakeformation.amazonaws.com
            Action:
              - sts:AssumeRole
      RoleName: !Sub LFRegisterLocationServiceRole-${AWS::StackName}
      Path: /

  S3DataLakePolicy:
    DependsOn: LFRegisterLocationServiceRole
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub S3DataLakePolicy-${AWS::StackName}
      PolicyDocument: 
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Action:
              - lakeformation:RegisterResource
            Resource: !Sub arn:aws:s3:::${DataLakeBucketName}
          -
            Effect: "Allow"
            Action:
              - s3:GetObject
              - s3:PutObject
            Resource: !Sub arn:aws:s3:::${DataLakeBucketName}/*
          -
            Effect: "Allow"
            Action:
              - s3:ListBucket
            Resource: !Sub arn:aws:s3:::${DataLakeBucketName}
      Roles: 
        - !Ref LFRegisterLocationServiceRole

  LFTbacDatabasePermissionForDataLakeAdminUser:
    DependsOn: 
      - LakeFormationDatabaseTbac
    Type: AWS::LakeFormation::Permissions
    Properties:
      DataLakePrincipal:
        DataLakePrincipalIdentifier: !GetAtt 'DatalakeAdminUser.Arn'
      Permissions:
        - ALL
        - ALTER
        - CREATE_TABLE
        - DESCRIBE
        - DROP
      PermissionsWithGrantOption:
        - ALL
        - ALTER
        - CREATE_TABLE
        - DESCRIBE
        - DROP
      Resource:
        DatabaseResource:
          Name: !Ref DatabaseNameTbac
    
  LFNamedResourceDatabasePermissionForDataLakeAdminUser:
    DependsOn: 
      - LakeFormationDatabaseNamedResource
    Type: AWS::LakeFormation::Permissions
    Properties:
      DataLakePrincipal:
        DataLakePrincipalIdentifier: !GetAtt 'DatalakeAdminUser.Arn'
      Permissions:
        - ALL
        - ALTER
        - CREATE_TABLE
        - DESCRIBE
        - DROP
      PermissionsWithGrantOption:
        - ALL
        - ALTER
        - CREATE_TABLE
        - DESCRIBE
        - DROP
      Resource:
        DatabaseResource:
          Name: !Ref DatabaseNameNamedResource

  LakeFormationDatabaseTbac:
    Type: AWS::Glue::Database
    Properties: 
      CatalogId: !Ref AWS::AccountId
      DatabaseInput: 
        Name: !Ref DatabaseNameTbac

  LakeFormationTableTbac:
    DependsOn: LakeFormationDatabaseTbac
    Type: AWS::Glue::Table
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseName: !Ref DatabaseNameTbac
      TableInput:
        Name: !Ref TableNameTbac
        TableType: EXTERNAL_TABLE
        Parameters: {
          "classification": "parquet"
        }
        StorageDescriptor:
          Location: !Sub 's3://${DataLakeBucketName}/data/amazon_reviews_parquet/'
          InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          Columns:
            - Name: marketplace
              Type: string
            - Name: customer_id
              Type: string
            - Name: review_id
              Type: string
            - Name: product_id
              Type: string
            - Name: product_parent
              Type: string
            - Name: product_title
              Type: string
            - Name: star_rating
              Type: int
            - Name: helpful_votes
              Type: int
            - Name: total_votes
              Type: int
            - Name: vine
              Type: string
            - Name: verified_purchase
              Type: string
            - Name: review_headline
              Type: string
            - Name: review_body
              Type: string
            - Name: review_date
              Type: date
            - Name: year
              Type: int
          SerdeInfo:
            SerializationLibrary: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
            Parameters: {}
          Parameters:
            serialization.format: 1
        PartitionKeys:
          - Name: product_category
            Type: string

  LakeFormationTablePartitionVideoTbac:
    DependsOn: LakeFormationTableTbac
    Type: AWS::Glue::Partition
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseName: !Ref DatabaseNameTbac
      TableName: !Ref TableNameTbac
      PartitionInput:
        Parameters: {}
        Values:
          - Mobile_Electronics
        StorageDescriptor:
          Location: !Sub 's3://${DataLakeBucketName}/data/amazon_reviews_parquet/product_category=Video/'
          InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          Columns:
            - Name: marketplace
              Type: string
            - Name: customer_id
              Type: string
            - Name: review_id
              Type: string
            - Name: product_id
              Type: string
            - Name: product_parent
              Type: string
            - Name: product_title
              Type: string
            - Name: star_rating
              Type: int
            - Name: helpful_votes
              Type: int
            - Name: total_votes
              Type: int
            - Name: vine
              Type: string
            - Name: verified_purchase
              Type: string
            - Name: review_headline
              Type: string
            - Name: review_body
              Type: string
            - Name: review_date
              Type: date
            - Name: year
              Type: int
          SerdeInfo:
            SerializationLibrary: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
            Parameters: {}
          Parameters:
            serialization.format: 1

  LakeFormationDatabaseNamedResource:
    Type: AWS::Glue::Database
    Properties: 
      CatalogId: !Ref AWS::AccountId
      DatabaseInput: 
        Name: !Ref DatabaseNameNamedResource

  LakeFormationTableNamedResource:
    DependsOn: LakeFormationDatabaseNamedResource
    Type: AWS::Glue::Table
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseName: !Ref DatabaseNameNamedResource
      TableInput:
        Name: !Ref TableNameNamedResource
        TableType: EXTERNAL_TABLE
        Parameters: {
          "classification": "parquet"
        }
        StorageDescriptor:
          Location: !Sub 's3://${DataLakeBucketName}/data/amazon_reviews_parquet/'
          InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          Columns:
            - Name: marketplace
              Type: string
            - Name: customer_id
              Type: string
            - Name: review_id
              Type: string
            - Name: product_id
              Type: string
            - Name: product_parent
              Type: string
            - Name: product_title
              Type: string
            - Name: star_rating
              Type: int
            - Name: helpful_votes
              Type: int
            - Name: total_votes
              Type: int
            - Name: vine
              Type: string
            - Name: verified_purchase
              Type: string
            - Name: review_headline
              Type: string
            - Name: review_body
              Type: string
            - Name: review_date
              Type: date
            - Name: year
              Type: int
          SerdeInfo:
            SerializationLibrary: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
            Parameters: {}
          Parameters:
            serialization.format: 1
        PartitionKeys:
          - Name: product_category
            Type: string

  LakeFormationTablePartitionVideoNamedResource:
    DependsOn: LakeFormationTableNamedResource
    Type: AWS::Glue::Partition
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseName: !Ref DatabaseNameNamedResource
      TableName: !Ref TableNameNamedResource
      PartitionInput:
        Parameters: {}
        Values:
          - Mobile_Electronics
        StorageDescriptor:
          Location: !Sub 's3://${DataLakeBucketName}/data/amazon_reviews_parquet/product_category=Video/'
          InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          Columns:
            - Name: marketplace
              Type: string
            - Name: customer_id
              Type: string
            - Name: review_id
              Type: string
            - Name: product_id
              Type: string
            - Name: product_parent
              Type: string
            - Name: product_title
              Type: string
            - Name: star_rating
              Type: int
            - Name: helpful_votes
              Type: int
            - Name: total_votes
              Type: int
            - Name: vine
              Type: string
            - Name: verified_purchase
              Type: string
            - Name: review_headline
              Type: string
            - Name: review_body
              Type: string
            - Name: review_date
              Type: date
            - Name: year
              Type: int
          SerdeInfo:
            SerializationLibrary: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
            Parameters: {}
          Parameters:
            serialization.format: 1


